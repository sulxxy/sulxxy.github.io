<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>COMMENTARIUM</title>
  
  
  <link href="http://www.liuzhiwei.me/atom.xml" rel="self"/>
  
  <link href="http://www.liuzhiwei.me/"/>
  <updated>2022-08-21T13:06:29.538Z</updated>
  <id>http://www.liuzhiwei.me/</id>
  
  <author>
    <name>Zhiwei Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>XML Schema</title>
    <link href="http://www.liuzhiwei.me/xml_schema/"/>
    <id>http://www.liuzhiwei.me/xml_schema/</id>
    <published>2022-08-19T21:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;</summary>
      
    
    
    
    <category term="misc_tech_note" scheme="http://www.liuzhiwei.me/categories/misc-tech-note/"/>
    
    
  </entry>
  
  <entry>
    <title>auto in CPP</title>
    <link href="http://www.liuzhiwei.me/auto_in_cpp/"/>
    <id>http://www.liuzhiwei.me/auto_in_cpp/</id>
    <published>2022-08-17T21:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>auto&amp;, auto</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;auto&amp;amp;, auto&lt;/p&gt;
</summary>
      
    
    
    
    <category term="programming" scheme="http://www.liuzhiwei.me/categories/programming/"/>
    
    
  </entry>
  
  <entry>
    <title>Write A Random Generator By Yourself</title>
    <link href="http://www.liuzhiwei.me/random_generator/"/>
    <id>http://www.liuzhiwei.me/random_generator/</id>
    <published>2022-08-15T21:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;</summary>
      
    
    
    
    <category term="programming" scheme="http://www.liuzhiwei.me/categories/programming/"/>
    
    
  </entry>
  
  <entry>
    <title>Singleton in CPP</title>
    <link href="http://www.liuzhiwei.me/singleton_in_cpp/"/>
    <id>http://www.liuzhiwei.me/singleton_in_cpp/</id>
    <published>2022-08-15T21:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::once_flag</span><br><span class="line">std::call_once</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;ta</summary>
      
    
    
    
    <category term="programming" scheme="http://www.liuzhiwei.me/categories/programming/"/>
    
    
  </entry>
  
  <entry>
    <title>Publish Your WordPress Post in Automation with GitHub Actions</title>
    <link href="http://www.liuzhiwei.me/automated_wordpress_post/"/>
    <id>http://www.liuzhiwei.me/automated_wordpress_post/</id>
    <published>2022-08-15T18:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Python script:</p><ol><li>markdown with mathjax</li><li>convert markdown to html</li><li>Post to WordPress via restful <a href="https://developer.wordpress.org/rest-api/reference/">API</a></li></ol><p>Trigger the above script through GitHub action.</p><ol><li>setup application password</li><li>Optional: only trigger action for specific commit messages</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Python script:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ma</summary>
      
    
    
    
    <category term="misc_tech_note" scheme="http://www.liuzhiwei.me/categories/misc-tech-note/"/>
    
    
  </entry>
  
  <entry>
    <title>Difference Between Gradient Descent and Stochastic Gradient Descent</title>
    <link href="http://www.liuzhiwei.me/sgd_and_gd/"/>
    <id>http://www.liuzhiwei.me/sgd_and_gd/</id>
    <published>2018-02-26T11:13:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This post mainly discusses the difference between gradient gescent (a.k.a. vanilla gradient descent or batch gradient descent) and stochastic gradient descent (a.k.a. online gradient descent). We firstly show and compare the 2 alogorithms’ implementations, which is quite simple. After that, we will analyse these 2 algorithms from the convergence rate perspective. At the end, the summaries are given.</p><span id="more"></span><h1 id="Algorithm-Implementation"><a href="#Algorithm-Implementation" class="headerlink" title="Algorithm Implementation"></a>Algorithm Implementation</h1><p>In this part, we mainly concentrate on the implementation of both algorithms to get an intuive difference between them. Assumes we have loss function $L(\mathbf{w}; \mathbf{x})$, in which $\mathbf{w}$ is the parameters to train and $\mathbf{x}$ is the input data.<br>For gradient descent (GD),</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">loss, w, T, X, eta</span>):</span><br><span class="line">    :param loss: the loss function</span><br><span class="line">    :param w: trainable parameters</span><br><span class="line">    :param T: iterations to train</span><br><span class="line">    :param X: data points</span><br><span class="line">    :param eta: the learning rate</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        gradient_sum = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> X:</span><br><span class="line">            cur_gradient = loss.subgradient(w, x)</span><br><span class="line">            gradient_sum = element_wise_add(gradient_sum, cur_gradient)</span><br><span class="line">        gradient = gradient_sum/X.size()</span><br><span class="line">        w = w - eta * gradient</span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></table></figure><p>Note that in order to show the main difference with later SGD algorithm, above code snippet is not optimized (i.e. vectorized).</p><p>For stochastic gradient descent (SGD), </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stochastic_gradient_descent</span>(<span class="params">loss, w, T, X, eta</span>):</span><br><span class="line">    :param loss: the loss function</span><br><span class="line">    :param w: trainable parameters</span><br><span class="line">    :param T: iterations to train</span><br><span class="line">    :param X: data points</span><br><span class="line">    :param eta: the learning rate</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        x = rand_choose(X)</span><br><span class="line">        cur_gradient = loss.subgradient(w, x)</span><br><span class="line">        w = w - eta * gradient</span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></table></figure><p>As we could see from above 2 pseudo code snippets, the key difference is the SGD randomly chooses a data point to optimize, while the GD optimize on the whole dataset. As a result, the time complexity of GD and SGD are $\mathcal{O}(TN)$<br>(without considering vectorization) and $\mathcal{O}(T)$, respectively. Both implementations are simple and easily understood. </p><h1 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h1><p>This part analyses the convergence rate of the 2 algorithms mathematically. Since nonconvex optimization problems are extremely complex (NP-hard), we only discuss convex optimization here, which assumes the loss functions are convex.<br>The simplest case is that loss function $f(\mathbf{x})$ is $\gamma$-well-conditioned (which means the function is both $\alpha$-strongly convex and $\beta$-smooth).</p><h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>Set $h_t &#x3D; f(\mathbf{x}_t) - f(\mathbf{x}^{*})$, where $\mathbf{x}^*$ is the (unknown) optimal point. we will show that for unconstrained minimization: </p><p>$$h_{t+1} \leq h_{1}e^{-\gamma t}$$</p><p>in which $\eta_t &#x3D; \frac{1}{\beta}$.</p><p>According to strongly convexity, for any $\mathbf{x}, \mathbf{y} \in \mathcal{K}$:<br>$$<br>\begin{align}<br>f(\mathbf{y}) &amp; \geq f(\mathbf{x}) + \nabla f(\mathbf{x})^\top (\mathbf{y}-\mathbf{x}) + \frac{\alpha}{2} \Vert\mathbf{x} - \mathbf{y}\Vert^2 \<br>&amp; \geq \min_{\mathbf{z}}\Bigl\{f(\mathbf{x}) + \nabla f(\mathbf{x})^\top (\mathbf{z}-\mathbf{x}) + \frac{\alpha}{2} \Vert\mathbf{x} - \mathbf{z}\Vert^2\Bigr\} \<br>&amp; &#x3D; f(\mathbf{x}) - \frac{1}{2\alpha}\Vert\nabla f(\mathbf{x})\Vert^2<br>\end{align}<br>$$</p><p>In particular, take $\mathbf{x} &#x3D; \mathbf{x}_t$ and $\mathbf{y} &#x3D; \mathbf{x}^*$,</p><p>$$<br>\nabla f(\mathbf{x}_t) \geq 2\alpha(f(\mathbf{x}_t) - f(\mathbf{x}^*)) &#x3D; 2\alpha h_t<br>$$</p><p>Meanwhile, according to the $\beta$-smoothness,</p><p>$$<br>\begin{align}<br>h_{t+1} - h_t &amp; &#x3D; f(\mathbf{x}_{t+1}) - f(\mathbf{x}_t) \<br>&amp; \leq \nabla f(\mathbf{x}_t)^\top (\mathbf{x}_{t+1} - \mathbf{x}_{t}) + \frac{\beta}{2}\Vert \mathbf{x}_{t+1} - \mathbf{x}_t\Vert^2 \<br>&amp; &#x3D; -\eta_t \Vert \nabla f(\mathbf{x}_t) \Vert^2 + \frac{\beta}{2} \eta_t^2 \Vert \nabla f(\mathbf{x}_t) \Vert^2 \<br>&amp; &#x3D; - \frac{1}{2\beta}\Vert \nabla f(\mathbf{x}_t) \Vert^2 \<br>&amp; \leq -\frac{\alpha}{\beta}h_t<br>\end{align}<br>$$</p><p>Thus,</p><p>$$h_{t+1} \leq h_{t}(1-\frac{\alpha}{\beta} \leq \cdots \leq h_{1}(1-\gamma)^t \leq h_{1}e^{-\gamma t} \tag{2} \label{eq:2}$$</p><p>In order to make it comparable with later SGD analysis, we compute the <em>regret</em> $R_T &#x3D; \sum_{t&#x3D;1}^T f(\mathbf{x}_t) - \min_{x^* \in \mathcal{K}}\sum_{t&#x3D;1}^T f(\mathbf{x}^*) &#x3D; \sum_{t&#x3D;1}^T h_t$, according to $\ref{eq:2}$, </p><p>$$R_T \leq \frac{h_1}{e^\gamma - 1} (e^{-\gamma T} - 1) &#x3D; \mathcal{O}(e^{-\gamma T})$$</p><h2 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h2><p>SGD is an online optimizer, we use <em>regret</em> as measurement. Different with former mentioned formula, SGD’s regret is written as:</p><p>$$R_T &#x3D; \sum_{t&#x3D;1}^T f_t(\mathbf{x}_t) - \min_{\mathbf{x}^* \in \mathcal{K}} \sum_{t&#x3D;1}^T f_t(\mathbf{x}^*)$$</p><p>in which the fuction $f_t({\mathbf{x}})$ is different at each iteration since $\mathbf{x}$ are randomly chosed in each iteration in this algorithm. We can prove that </p><p>$$<br>R_T \leq \frac{3}{2}GD\sqrt{T}<br>$$<br>where $G$ is the lipschitz constant and $D$ is the diameter of decision set.</p><p>The 2 algorithms reprensents 2 different optimization schemes: offline optimization (GD) and online optimization (SGD).</p><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] E. Hazan, “Introduction to Online Convex Optimization,” Found. Trends® Optim., vol. 2, no. 3–4, pp. 157–325, 2016.</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;This post mainly discusses the difference between gradient gescent (a.k.a. vanilla gradient descent or batch gradient descent) and stochastic gradient descent (a.k.a. online gradient descent). We firstly show and compare the 2 alogorithms’ implementations, which is quite simple. After that, we will analyse these 2 algorithms from the convergence rate perspective. At the end, the summaries are given.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Support Vector Machine</title>
    <link href="http://www.liuzhiwei.me/svm/"/>
    <id>http://www.liuzhiwei.me/svm/</id>
    <published>2018-01-30T21:13:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Maximum-Hard-Margin-Classifier"><a href="#Maximum-Hard-Margin-Classifier" class="headerlink" title="Maximum(Hard) Margin Classifier"></a>Maximum(Hard) Margin Classifier</h1><p>Let us start from the simplest situation: 2-class classification problem using linear models with the form:<br>$$ \mathcal{y}(\mathbf{x}) &#x3D; \mathbf{w}^\top \mathbf{x} + b \label{eq:1}\tag{1}$$<br>The training set data comprises $N$ input vectors $\mathbf{x_1}$, …, $\mathbf{x_N}$, with corresponding labels $\mathcal{t}_1$, …, $\mathcal{t}_N$, where $\mathcal{t_n} \in \{-1, 1\}$.</p><span id="more"></span><p>We shall assume that the training set is linearly separable now, then there must exist at least one choice of the parameter $\mathbf{w}$ and $b$ such that the data points could be split into 2 parts. In support vector machines, the decision boundary is the one for which the margin is maximized. Margin is the smallest distance between the decision boundary and any of the samples.<br>Now we know: the distance of a point $\mathbf{x}_n$ to the decision surface is(<em>todo</em>: explaination here):<br>$$ \frac{\mathcal{t}_n\mathcal{y}(\mathbf{x}_n)}{\Vert{\mathbf{w}}\Vert} &#x3D; \frac{\mathcal{t}_n(\mathbf{w}^\top \mathbf{x}_n + b)}{\Vert \mathbf{w}\Vert} \label{eq: 2} \tag{2}$$<br>The margin is given by the perpendicular distance to the closest point $\mathbf{x}_n$ from the data set and we wish to find a $\mathbf{w}$ and $b$ such that we got maximum distance. Thus the maximum margin solution is found by solving:<br>$$ \underset{\mathbf{w}, b}{\arg\max} , \Bigl\{\frac{1}{\Vert \mathbf{w}\Vert}\min_{\mathcal{n}} , \bigl[{\mathcal{t}_n(\mathbf{w}^\top \mathbf{x}_n + b)}\bigr]\Bigl\} \label{eq: 3} \tag{3}$$<br>We could solve ($\ref{eq: 3}$) using Lagrange multipliers, but we need do some conversion before that. It is not hard to find that if we rescale $\mathbf{w} \to \mathcal{k}\mathbf{w}$ and $ b \to \mathcal{k}b$, the distance from any point $\mathbf{x}_n$ to the decision surface, given by $\frac{\mathcal{t}_n\mathcal{y}(\mathbf{x}_n)}{\Vert \mathbf{w} \Vert} $ is unchanged. So we are free to set<br>$$ {\mathcal{t}_n(\mathbf{w}^\top \mathbf{x}_n + b)} &#x3D; 1 \label{eq:4} \tag{4}$$<br>for the point that is closest to the surface. In this case, all the points will satisfy the constraint:<br>$$ {\mathcal{t}_n(\mathbf{w}^\top \mathbf{x}_n + b)} \geq 1, \quad n&#x3D;1,2, \ldots, N. \label{eq:5} \tag{5}$$<br>So now the optimization problem simply requires that we maximize ${\Vert \mathbf{w} \Vert}^{-1}$, which is equivalent to minimizing ${\Vert \mathbf{w} \Vert}^2$. So we have to solve the problem:<br>$$ \underset{\mathbf{w}, b}{\arg\min} , \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 \label{eq:6} \tag{6}$$<br>subject to the contraints given by ($\ref{eq:5}$). This is called <strong>primal problem</strong>, $\mathbf{w}, b$ are the primal variables.<br>As I said, we can use Lagrange multipliers to solve this problem. We indroduce Lagrange mulitpliers vector $\mathbf{a} &#x3D; (a_1, a_2, \ldots, a_N)^\top, a_n \geq 0$, each $a_n$ corresponding each of the constraints in $\ref{eq:5}$. Now we have the Lagrangian function:<br>$$ \mathcal{L}(\mathbf{w}, b, \mathbf{a}) &#x3D; \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 - \sum_{n&#x3D;1}^N , a_n , \bigl\{ {\mathcal{t}_n(\mathbf{w}^\top \mathbf{x}_n + b)} - 1\bigl\} \label{eq:7}\tag{7}$$<br>This is called <strong>dual problem</strong>. To solve ($\ref{eq:7}$), we need to set the derivatives of $\mathcal{L}(\mathbf{w}, b, \mathbf{a})$ w.r.t. the primal variables $\mathbf{w}, b$ to zeros first. So we got:<br>$$<br>\begin{align}<br>\mathbf{w} &amp; &#x3D; \sum_{n&#x3D;1}^N , a_nt_n\mathbf{x}_n \label{eq:8}\tag{8} \<br>0 &amp; &#x3D; \sum_{n&#x3D;1}^N , a_nt_n \label{eq:9}\tag{9}<br>\end{align}<br>$$<br>put ($\ref{eq:8}, \ref{eq:9}$) into $\mathcal{L}(\mathbf{w}, b, \mathbf{a})$, we could eliminate $\mathbf{w}, b$, and now we need to maximize:<br>$$ \tilde{\mathcal{L}}(\mathbf{a}) &#x3D; \sum_{n&#x3D;1}^N , a_n - \frac{1}{2} \sum_{n,m&#x3D;1}^N , a_na_mt_nt_m\mathbf{x}_n^\top\mathbf{x}_m \label{eq:10}\tag{10}$$<br>w.r.t. $\mathbf{a}$, s.t. the constraints:<br>$$<br>\begin{align}<br>a_n  \geq 0, \quad n &#x3D; 1, \ldots, N. \label{eq:11} \tag{11} \<br>\sum_{n&#x3D;1}^N , a_nt_n  &#x3D; 0 \label{eq:12} \tag{12}<br>\end{align}<br>$$<br>Now, as we could see, ($\ref{eq:10}$) is still a quadratic programming problem, but it is easier then ($\ref{eq:6}$) since only 1 variable left. This can be solved using <strong>Sequential Minimal Optimization (SMO)</strong> algorithm. Since it will take a long page to introduce this algorithm, I put it in another post: <a href="http://liuzhiwei.me/SMO">Sequential Minimal Optimization Algorithm</a>.<br>Now assuming we have already got the optimized $\mathbf{a}$ through SMO algorithm, saying $\mathbf{a}^*$. In order to classify new data points, we evaluate the sign of $\mathcal{y}(\mathbf{x})$ defined by ($\ref{eq:1}$). Considered ($\ref{eq:8}$), we have:<br>$$ \mathcal{y}(\mathbf{x}) &#x3D; \sum_{n&#x3D;1}^N , a_n^*y_n\mathbf{x}_n^\top\mathbf{x} + b \label{eq:13} \tag{13} $$<br>We shall notice that $a_n^*$ is the Lagrangian multiplier in ($\ref{eq:7}$), and each $a_n^*$ corresponds to one data point $(\mathbf{x}_n, y_n)$.<br>We also need to know that a constrained optimization of this form satisfies the KKT conditions, in which the following properties hold:<br>$$<br>\begin{align}<br>a_n^* &amp; \geq 0 \label{eq:14} \tag{14} \<br>t_n\mathcal{y}(\mathbf{x}_n) -1 &amp; \geq 0 \label{eq:15} \tag{15} \<br>a_n^* \bigl\{t_n\mathcal{y}(\mathbf{x}_n) - 1\bigr\} &amp; &#x3D; 0 \label{eq:16} \tag{16}<br>\end{align}<br>$$<br>That is to say, for each data point $(\mathbf{x}_n, \mathcal{y}_n)$, either $a_n^* &#x3D; 0$ or $ t_n\mathcal{y}(\mathbf{x}_n) - 1 &#x3D; 0 $ satisfied. Any points for which $a_n^* &#x3D; 0$ will not appear in the sum in ($\ref{eq:13}$) and hence play no role in making prediction. On the other hand, the rest points will affect the prediction. Those points are called <em>support vectors</em>. And because $ t_n\mathcal{y}(\mathbf{x}_n) - 1 &#x3D; 0 $ satisfied, they lie on the maximum margin hyperplanes in feature space.<br>Also noting that $ t_n\mathcal{y}(\mathbf{x}_n) - 1 &#x3D; 0 $ and ($\ref{eq:13}$), we have:<br>$$ t_n \Bigl( \sum_{m \in S} , a_m t_m \mathbf{x}_m^\top\mathbf{x}_n + b \Bigr) &#x3D; 1 \label{eq:17} \tag{17} $$<br>in which $S$ is the set of indices of support vectors.<br>While we can choose a random $n$ to obtain $b$, a more stable way is first multiplying through by $t_n$, making use of $t_n^2 &#x3D; 1 $, and then averaging these equations over all support vectors and solving for $b$ to give:<br>$$ b &#x3D; \frac{1}{N_S}\sum_{n \in S} , \Bigl(t_n - \sum_{m \in S} , a_m t_m \mathbf{x}_m^\top\mathbf{x}_n \Bigr) \label{eq:18} \tag{18} $$<br>where $N_S$ is the total number of support vectors.</p><h2 id="Kernel-tricks"><a href="#Kernel-tricks" class="headerlink" title="Kernel tricks"></a>Kernel tricks</h2><p>You may already notice that there are always the term $\mathbf{x}_n^\top\mathbf{x}$ or $\mathbf{x}_m^\top\mathbf{x}_n$, such as in ($\ref{eq:10}, \ref{eq:13}, \ref{eq:17}, \ref{eq:18}$), we can replace them using kernel functions, let’s say: $\mathcal{k}(\mathbf{x}_n, \mathbf{x}_m)$ or $\mathcal{k}(\mathbf{x}, \mathbf{x}_n)$. Also we need to define a feature space transformation for the input data $\mathbf{x}$ in ($\ref{eq:1}$), denoting as $\phi(\mathbf{x})$. So ($\ref{eq:1}$) becomes:<br>$$ \mathcal{y}(\mathbf{x}) &#x3D; \mathbf{w}^\top \phi(\mathcal{x}) + b \label{eq:19}\tag{19}$$<br>More details can be found in the post <a href="http://liuzhiwei.me/Kernel_Methods">Kernel Methods</a>. And in the later discussion, I will use ($\ref{eq:19}$) instead of ($\ref{eq:1}$) since kernel version is more general.</p><h1 id="Soft-Margin-Classifier"><a href="#Soft-Margin-Classifier" class="headerlink" title="Soft Margin Classifier"></a>Soft Margin Classifier</h1><p>In the previous discussion, we assumed that the training points are linearly separable in the feature space $\phi(\mathbf{x})$. In practice, however, the class-conditional distributions may overlap. In this case, if we still try to find the exact separation, the result might lead to overfitting and poor generalization.<br>To avoid this, the support vector machines should allow some of training data points to be misclassified. To do this, we introduce <em>slack variables</em>, denoted as $\xi_n \geq 0$ where $n &#x3D; 1, \ldots, N$, one slack variable corresponds one training data point. These are defined by $\xi_n &#x3D; 0$ for data points that are on or inside the correct margin boundary and $\xi_n &#x3D; \vert t_n - y(\mathbf{x}_n)\vert$ for the other points. Thus for the data points lying on the decision boundary $\mathcal{y}(\mathbf{x}_n) &#x3D; 0 $ will have $\xi_n &#x3D; 1 $, and points with $\xi_n \gt 1$ will be misclassified. Thus the classification constraints are:<br>$$ t_n\mathcal{y}(\mathbf{x}_n) \geq 1 - \xi_n, \quad n&#x3D;1, \ldots, N. \label{eq:20} \tag{20} $$<br>in which the slack variables are with contraints $\xi_n \geq 0$. From ($\ref{eq:20}$) we know that:</p><ul><li>for the points with $\xi_n &#x3D; 0 $: they lie on the margin or on the correct side of margin</li><li>for the points with $0 \lt \xi_n \lt 1$: they lie inside the margin but on the right side of decision boundary</li><li>for the points with $\xi_n &#x3D; 1$: they exactly lie on the decision boundary</li><li>for the points with $\xi_n \gt 1$: they are misclassified</li></ul><p>So now we need to minimize:<br>$$ C\sum_{n&#x3D;1}^{N} , \xi_n + \frac{1}{2} {\Vert \mathbf{w} \Vert}^2 \label{eq:21}\tag{21} $$<br>subject to the constraints:<br>$$<br>\begin{align}<br>t_n\mathcal{y}(\mathbf{x}_n) &amp; \geq 1 - \xi_n, \quad n&#x3D;1, \ldots, N. \label{eq:22} \tag{22} \<br>\xi_n &amp; \geq 0, \quad n&#x3D;1, \ldots, N. \label{eq:23} \tag{23}<br>\end{align}<br>$$<br>in which $C \gt 0$ controls the trade-off between the slack variable penalty and the margin. Notice that if $C \to \infty$, we will be back to the earlier support vector machine for separable data since the points misclassified or inside margin will be given a large penalty coefficient.<br>So now we need to minimize ($\ref{eq:21}$) subject to constraints ($\ref{eq:22}, \ref{eq:23}$). Similarly, we also use Lagrange multipliers to solve this problem. The  corresponding Lagrangian is:<br>$$ \mathcal{L}(\mathbf{w}, b, \mathbf{\xi}, \mathbf{a}, \mathbf{\mu}) &#x3D; \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 + C \sum_{n&#x3D;1}^N\xi_n - \sum_{n&#x3D;1}^{N}a_n\bigl\{t_n\mathcal{y}(\mathbf{x}_n) - 1 + \xi_n\bigr\} - \sum_{n&#x3D;1}^{N}\mu_n\xi_n \label{eq:24} \tag{24} $$<br>where $\{a_n \geq 0\}$ and $\{\mu_n \geq 0\}$ are the Lagrange mulitpliers and $\mathbf{w}, b, \{\xi_n\}$ are the primal variables. The KKT conditions are:<br>$$<br>\begin{align}<br>a_n &amp; \geq 0 \label{eq:25} \tag{25} \<br>t_n\mathcal{y}(\mathbf{x}_n) - 1 + \xi_n &amp; \geq 0 \label{eq:26} \tag{26} \<br>a_n\bigl(t_n\mathcal{y}(\mathbf{x}_n) - 1 + \xi_n\bigr) &amp; &#x3D; 0 \label{eq:27} \tag{27} \<br>\mu_n &amp; \geq 0 \label{eq:28} \tag{28} \<br>\xi_n &amp; \geq 0 \label{eq:29} \tag{29}  \<br>\mu_n\xi_n &amp; &#x3D; 0 \label{eq:30} \tag{30}<br>\end{align}<br>$$<br>where $n&#x3D;1,\ldots,N$.</p><p>Now we need to set the partial derivatives w.r.t. the primal variables ($\mathbf{w}, b, \{\xi_n\}$) in ($\ref{eq:24}$) to zeros. Then we got:<br>$$<br>\begin{align}<br>\frac{\partial \mathcal{L}}{\partial \mathbf{w}} &#x3D; 0; &amp; \Rightarrow ;\mathbf{w} &#x3D; \sum_{n&#x3D;1}^{N}a_nt_n\phi(\mathbf{x}_n) \label{eq:31} \tag{31} \<br>\frac{\partial \mathcal{L}}{\partial b} &#x3D; 0; &amp; \Rightarrow; \sum_{n&#x3D;1}^{N}a_nt_n &#x3D; 0 \label{eq:32} \tag{32} \<br>\frac{\partial \mathcal{L}}{\partial \xi_n} &#x3D; 0; &amp; \Rightarrow ;a_n &#x3D; C - \mu_n \label{eq:33} \tag{33} \<br>\end{align}<br>$$<br>Now we can eliminate $\mathbf{w}, b, \{\xi_n\}$ using ($\ref{eq:31}, \ref{eq:32}, \ref{eq:33}$). Then we got the dual Lagraingian:<br>$$\tilde{\mathcal{L}}(\mathbf{a}) &#x3D; \sum_{n&#x3D;1}^{N}a_n - \frac{1}{2}\sum_{n&#x3D;1}^N\sum_{m&#x3D;1}^N a_n a_m t_n t_m \mathcal{k}(\mathbf{x}_n, \mathbf{x}_m) \label{eq:34} \tag{34}$$<br>You may find that ($\ref{eq:34}$) is exactly same with the separable one ($\ref{eq:10}$), the difference is the constraints. Based on ($\ref{eq:28}, \ref{eq:33}$), we know that:<br>$$ 0 \leq a_n \leq C, n&#x3D;1,\ldots, N \label{eq:35} \tag{35} $$<br>Now our mission is to maximize ($\ref{eq:34}$) with respect to $\{a_n\}$ subject to constraints ($\ref{eq:32}, \ref{eq:35}$). Again, we got a quadratic programming problem, see <a href="http://liuzhiwei.me/SMO">Sequential Minimal Optimization Algorithm</a> for more details.<br>We can do some explainations on this result:</p><ul><li>for those points with $a_n &#x3D; 0$: they do not contribute to the prediction (see ($\ref{eq:16}$ and its explaination there)), ignore them. </li><li>for those points with $a_n \gt 0$:<br>  according to ($\ref{eq:27}$), we know:<br>  $$ t_n\mathcal{y}(\mathbf{x}_n) &#x3D; 1 - \xi_n \label{eq:36} \tag{36} $$<ul><li>if $a_n \lt C$:<br>  ($\ref{eq:33}$) implies $\mu_n \gt 0$, which means $\xi_n &#x3D; 0$ based on ($\ref{eq:30}$). So this points lie on the margins.</li><li>if $a_n &#x3D; C$:<br>  if $\xi_n \leq 1$, the points are inside margin and correctly classified.  if $\xi_n \gt 0$, the points are misclassified.</li></ul></li></ul><p>To determine the paramter $b$, the support vectors for which $0 \lt a_n \lt C$ have $\xi_n &#x3D; 0$ so that $t_n\mathcal{y}(\mathbf{x}_n) &#x3D; 1 $. As a result:<br>$$ t_n\Bigl(\sum_{m \in S} a_m t_m \mathcal{k}(\mathbf{x}_n, \mathbf{x}_m) + b\Bigr) &#x3D; 1 \label{eq:37} \tag{37} $$<br>where $S$ is the set of indices of support vectors.<br>similarly, the stable solution is averaging instead of randomly choosing one:<br>$$ b &#x3D; \frac{1}{N_{\mathcal{M}}}\sum_{n \in \mathcal{M}} \Bigl(t_n - \sum_{m \in S} a_m t_m \mathcal{k}(\mathbf{x}_n, \mathbf{x}_m)\Bigr) \label{eq:38} \tag{38} $$<br>where $\mathcal{M}$ is the set of indices of data points having $0 \lt a_n \lt C$.</p><h1 id="Support-Vector-Regression"><a href="#Support-Vector-Regression" class="headerlink" title="Support Vector Regression"></a>Support Vector Regression</h1><p>Different to simple <a href="http://liuzhiwei.me/Linear_Regression">linear regression</a> using quadratic error function, SVR uses an $\epsilon$<em>-insensitive error function</em>, ehich is given by:<br>$$E_{\epsilon}(\mathcal{y}(\mathbf{x}) - t) &#x3D;<br>\begin{cases}<br>0, &amp; if \vert \mathcal{y}(\mathbf{x}) - t \vert \lt \epsilon; \<br>\vert \mathcal{y}(\mathbf{x}) - t \vert - \epsilon, &amp; otherwise<br>\end{cases}<br>\label{eq:39} \tag{39}<br>$$<br>We are supposed to minimize the regularized error function:<br>$$C\sum_{n&#x3D;1}^{N}E_{\epsilon}(\mathcal{y}(\mathbf{x}_n) - t_n) + \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 \label{eq:40} \tag{40} $$<br>where $\mathcal{y}(\mathbf{x}_n)$ is given by ($\ref{eq:19}$).<br>As before, we introduce slack variables for each data point $\mathbf{x}_n, n&#x3D;1,\ldots, N$. Now each point need 2 slack variables $\xi_n \geq 0$ and $\hat{\xi_n} \geq 0$, where $\xi_n \gt 0$ corresponds to a point for which $t_n \gt \mathcal{y}(\mathbf{x}_n) + \epsilon$, and $\hat{\xi_n} \gt 0$ corresponds to a point for which $t_n \lt \mathcal{y}(\mathbf{x}_n) - \epsilon$. $\xi_n &#x3D; 0$ and $\hat{\xi_n} &#x3D; 0$ are for the points inside the $\epsilon-\text{tube}$.<br>The error function for support vector regression can then be written as:<br>$$C\sum_{n&#x3D;1}^{N}(\xi_n + \hat{\xi_n}) + \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 \label{eq:41} \tag{41} $$<br>w.r.t. $\mathbf{w}, b, \xi_n, \hat{\xi_n}$, s.t.<br>$$<br>\begin{align}<br>\xi_n &amp; \geq 0 \label{eq:42} \tag{42}\<br>\xi_n &amp; \geq 0 \label{eq:43} \tag{43}\<br>t_n &amp; \leq \mathcal{y}(\mathbf{x}_n) + \epsilon + \xi_n \label{eq:44} \tag{44}\<br>t_n &amp; \geq \mathcal{y}(\mathbf{x}_n) - \epsilon - \hat{\xi_n} \label{eq:45} \tag{45}<br>\end{align}<br>$$<br>apply Lagrange mulitpliers $a_n \geq 0, \hat{a_n} \geq 0, \mu_n \geq 0, \hat{\mu_n} \geq 0$ just as before, we need to minimize the Lagrangian:<br>$$<br>\begin{align}<br>\mathcal{L}(\mathbf{w}, b, \mathbf{\xi}, \mathbf{\hat{\xi}}, \mathbf{a}, \mathbf{\hat{a}} , \mathbf{\mu}, \mathbf{\hat{\mu}} )  &#x3D;, &amp; C\sum_{n&#x3D;1}^{N}(\xi_n + \hat{\xi_n}) + \frac{1}{2}{\Vert \mathbf{w} \Vert}^2 \<br>&amp; - \sum_{n&#x3D;1}^{N}(\mu_n\xi_n + \hat{\mu_n}\hat{\xi_n}) \<br>&amp; - \sum_{n&#x3D;1}^Na_n(\epsilon + \xi_n + \mathcal{y}_n - t_n) \<br>&amp; - \sum_{n&#x3D;1}^Na_n(\epsilon + \hat{\xi_n} - \mathcal{y}_n + t_n)<br>\end{align} \label{eq:46} \tag{46}<br>$$<br>setting partial derivatives w.r.t. primal variables ($\mathbf{w}, b, \xi_n, \hat{\xi_n}$) to zeros:<br>$$<br>\begin{align}<br>\frac{\partial \mathcal{L}}{\partial \mathbf{w}} &#x3D; 0 ; &amp; \Rightarrow ; \mathbf{w} &#x3D; \sum_{n&#x3D;1}^{N}(a_n - \hat{a_n})\phi(\mathbf{x}_n) \label{eq:47} \tag{47}\<br>\frac{\partial \mathcal{L}}{\partial b} &#x3D; 0 ; &amp; \Rightarrow ;  \sum_{n&#x3D;1}^{N}(a_n - \hat{a_n}) &#x3D; 0 \label{eq:48} \tag{48}\<br>\frac{\partial \mathcal{L}}{\partial \xi_n} &#x3D; 0 ;  &amp; \Rightarrow ; a_n + \mu_n &#x3D; C \label{eq:49} \tag{49}\<br>\frac{\partial \mathcal{L}}{\partial \hat{\xi_n}} &#x3D; 0 ; &amp; \Rightarrow ; \hat{a_n} + \hat{\mu_n} &#x3D; C \label{eq:50} \tag{50}<br>\end{align}<br>$$<br>eliminating the primal variables using those results, we need to maximize:<br>$$<br>\begin{align}<br>\tilde{\mathcal{L}}(\mathbf{a}, \mathbf{\hat{a}}) &#x3D; &amp; - \frac{1}{2} \sum_{n&#x3D;1}^{N}\sum_{m&#x3D;1}^{N}(a_n - \hat{a_n})(a_m - \hat{a_m})\mathcal{k}(\mathbf{x}_n, \mathbf{x}_m) \<br>&amp; - \epsilon\sum_{n&#x3D;1}^{N}(a_n + \hat{a_n}) \<br>&amp; + \sum_{n&#x3D;1}^{N}(a_n - \hat{a_n})t_n<br>\end{align}<br>\label{eq:51} \tag{51}<br>$$<br>since $\mu_n \geq 0, \hat{\mu_n} \geq 0$ and ($\ref{eq:49}, \ref{eq:50}$), we know that:<br>$$<br>\begin{align}<br>0 \leq a_n \leq C \label{eq:52} \tag{52} \<br>0 \leq \hat{a_n} \leq C \label{eq:53} \tag{53}<br>\end{align}<br>$$<br>The corresponding KKT conditions are:<br>$$<br>\begin{align}<br>a_n(\epsilon + \xi_n + \mathcal{y}_n - t_n) &amp; &#x3D; 0 \label{eq:54} \tag{54} \<br>\hat{a_n}(\epsilon + \hat{\xi_n} - \mathcal{y}_n + t_n) &amp; &#x3D; 0 \label{eq:55} \tag{55} \<br>(C - a_n)\xi_n &amp; &#x3D; 0 \label{eq:56} \tag{56} \<br>(C - \hat{a_n})\hat{\xi_n} &amp; &#x3D; 0 \label{eq:57} \tag{57} \<br>\end{align}<br>$$<br>from above, we could see that all points either has $a_n&#x3D;0$ or $\hat{a_n}&#x3D;0$ or both. And only those data points with $a_n \neq 0$ or $\hat{a_n} \neq 0$ contributes to predictions.</p><p>based on ($\ref{eq:19}, \ref{eq:47}$), we can do predictions for a new input $x$ using:<br>$$ \mathcal{y}(\mathbf{x}) &#x3D; \sum_{n&#x3D;1}^{N}(a_n - \hat{a_n})\mathcal{k}(\mathbf{x}, \mathbf{x}_n) + b \label{eq:58} \tag{58} $$<br>The parameter $b$ can be found by considering a data point $\mathbf{x}_n$ for which $0 \lt a_n \lt C$, finally we got:<br>$$ b &#x3D; t_n - \epsilon - \sum_{m&#x3D;1}^{N}(a_m - \hat{a_m})\mathcal{k}(\mathbf{x}_n, \mathbf{x}_m) \label{eq:59} \tag{59} $$</p><p>You may notice that we still have a parameter $\epsilon$ to determine. In practice, it is not easy to determine this value. To solve this problem, Scholkopf <em>et al.</em> (2000) proposed $\nu-SVM$, see reference 2 if interested. The programming part also has a problem related to $\nu-SVM$, go there if interested.</p><h1 id="Programming"><a href="#Programming" class="headerlink" title="Programming"></a>Programming</h1><p>See my GitHub repository <a href="https://github.com/sulxxy/ML_Algorithms/tree/master/SVM">ML_Algorithms</a> for details.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Bishop: Pattern Recognition and Machine Learning, Springer-Verlag, 2006</li><li>Scholkpf, B., A. Smola, R.C. Williamson, and P.L. Bartlett (2000). New support vector algorithms. <em>Neural Computation</em> <strong>12</strong>(5), 1207-1245</li></ol><h1 id="Related-Articles"><a href="#Related-Articles" class="headerlink" title="Related Articles"></a>Related Articles</h1><ol><li><a href="http://liuzhiwei.me/Kernel_Methods">Kernel Methods</a></li><li><a href="http://liuzhiwei.me/SMO">Sequential Minimal Optimization Algorithm</a></li><li><a href="http://liuzhiwei.me/Linear_Regression">Linear Regression</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Maximum-Hard-Margin-Classifier&quot;&gt;&lt;a href=&quot;#Maximum-Hard-Margin-Classifier&quot; class=&quot;headerlink&quot; title=&quot;Maximum(Hard) Margin Classifier&quot;&gt;&lt;/a&gt;Maximum(Hard) Margin Classifier&lt;/h1&gt;&lt;p&gt;Let us start from the simplest situation: 2-class classification problem using linear models with the form:&lt;br&gt;$$ \mathcal{y}(\mathbf{x}) &amp;#x3D; \mathbf{w}^\top \mathbf{x} + b \label{eq:1}\tag{1}$$&lt;br&gt;The training set data comprises $N$ input vectors $\mathbf{x_1}$, …, $\mathbf{x_N}$, with corresponding labels $\mathcal{t}_1$, …, $\mathcal{t}_N$, where $\mathcal{t_n} \in \{-1, 1\}$.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Kernel Methods</title>
    <link href="http://www.liuzhiwei.me/kernel_methods/"/>
    <id>http://www.liuzhiwei.me/kernel_methods/</id>
    <published>2018-01-26T11:13:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>temporary created in order to be referenced by other posts.</p><span id="more"></span>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;temporary created in order to be referenced by other posts.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Linear Regression</title>
    <link href="http://www.liuzhiwei.me/linear_regression/"/>
    <id>http://www.liuzhiwei.me/linear_regression/</id>
    <published>2018-01-26T11:13:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>temporary created in order to be referenced by other posts.</p><span id="more"></span>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;temporary created in order to be referenced by other posts.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Sequential Minimal Optimization Algorithm</title>
    <link href="http://www.liuzhiwei.me/smo/"/>
    <id>http://www.liuzhiwei.me/smo/</id>
    <published>2018-01-25T11:13:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>temporary created in order to be referenced by other posts.</p><span id="more"></span>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;temporary created in order to be referenced by other posts.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Perceptron and MLP</title>
    <link href="http://www.liuzhiwei.me/perceptron_and_mlp/"/>
    <id>http://www.liuzhiwei.me/perceptron_and_mlp/</id>
    <published>2017-12-10T16:05:26.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h1><p>Assume that only the means(or centroids) $\mathbf{\mu}_1$ and $\mathbf{\mu}_2$ of the 2 distributions are known. To predict the class of a new point, we could compare the distances to those 2 class means. That is,</p><span id="more"></span><p>$$<br>\begin{align}<br>\Vert \mathbf{x} - \mathbf{w}_1\Vert \lt \Vert \mathbf{x} - \mathbf{w}_2 \Vert \tag{1}\label{eq:1} \<br>\iff 0 \lt \mathbf{w}^\top\cdot{\mathbf{x}} - \beta  \tag{2}\label{eq:2}<br>\end{align}<br>$$<br>in formula $\ref{eq:2}$,<br>$$w&#x3D;\mathbf{\mu}_1 - \mathbf{\mu}_2 \tag{3}\label{eq:3}$$<br>Bias could be included to weight vector by:<br>$$<br>\tilde{\mathbf{x}} \leftarrow \left[<br>\begin{matrix}<br>1\<br>\mathbf{x}<br>\end{matrix}<br>\right],\\<br>\tilde{\mathbf{w}} \leftarrow \left[<br>\begin{matrix}<br>-\beta\<br>\mathbf{w}<br>\end{matrix}<br>\right]<br>\tag{4}\label{eq:4}<br>$$<br>Then, the error function could be defined as:<br>$$\epsilon(\tilde{\mathbf{w}}) &#x3D; - \sum_{m\in\mathcal{M}} \tilde{\mathbf{w}}^T \tilde{\mathbf{x}}_m y_m\tag{5}\label{eq:5}$$<br>Based on those, we could have the general framework for <strong>Perceptron Algorithm</strong>:</p><blockquote><p><strong>Computes</strong>: Normal vector $\mathbf{w}$ of decision hyperplane for binary classification<br><strong>Input</strong>: Data $\{(x_1, y_1), (x_2, y_2), …, (x_N, y_N)\}$, $x_i \in \Bbb{R}^D$, $y_i \in \{-1, +1\}$, learning rate $\eta$, iterations $N_{it}$.<br><strong>Procedure</strong>:<br>$\qquad \qquad$ w &#x3D; 1 &#x2F; D<br>$\qquad \qquad$ for i&#x3D;1 to $N_{it}$ do:<br>$\qquad \qquad \qquad$ Pick a random data point $x_i$<br>$\qquad \qquad \qquad$ if $w^Tx_iy_i &lt; 0$ then:<br>$\qquad \qquad \qquad \qquad$ $w &#x3D; w + \eta x_i y_i$<br>$\qquad \qquad \qquad$ end if<br>$\qquad \qquad$ end for<br><strong>Output</strong>: $w$</p></blockquote><p>To sum up, perceptron algorithm tries to find a hyperplane which could divide the data points exactly to 2 parts. However, this is a pretty ideal situation. In most case, the data are not separable. The simplest case is exclusive or($x_1 \oplus x_2$). Perceptron learning algorithm could not solve this problem. Concreately, the $w$ could not converge forever. There would be<br>To do this, <strong>Multiple Layer Perceptron(MLP)</strong> is introduced.</p><h1 id="Multiple-Layer-Perceptron"><a href="#Multiple-Layer-Perceptron" class="headerlink" title="Multiple Layer Perceptron"></a>Multiple Layer Perceptron</h1><p>Compared to perceptron, MLP has some hidden layers. In single layer perceptron, in every iteration, we train $\mathbf{w}$, and then check feasibility and optimize \mathbf{w}. After several iterations, we could got a nice $\mathbf{w}$. In MLP, the basic idea is almost the same but with more complex details(this kind of methodology is called <strong>Expection Maximum</strong>. I wrote a blog about this before, see <a href="http://liuzhiwei.me/EM_GMM/">EM and GMM</a> for more information). We call this algorithm <strong>Error BackPropagation</strong>.</p><h2 id="Error-BackPropagation"><a href="#Error-BackPropagation" class="headerlink" title="Error BackPropagation"></a>Error BackPropagation</h2><p>To explain and demostrate the procedure of error back propagation algorithm easily, I would like to use the example from the book <em>Pattern Recognition and Machine Learning [1]</em>.<br>  Below is the network architecture:<br>  we have a dataset $D &#x3D; \{(x_1, y_1), (x_2, y_2), …, (x_m, y_m)\}, , x_i \in \Bbb{R}^D, , y_i \in \Bbb{R}^K$, which means input has $D$ features and output is a $K$ dimensional vector. Also, we have $M$ hidden units as we could see from the diagram.<br><img src="http://7xssst.com1.z0.glb.clouddn.com/nn_example.jpg" alt="Network Architecture"></p><p>First, let us think about the needed parameters and their sizes respectively. Obviously we need weight $w$ and bias $b$. From the architecture, we know that each node in a layer has connections with all of the nodes of its (right-side, since what we are talking about is <strong>Forward Feed Network</strong>) adjacent layer(that is why MLP is also called <strong>Fully Connected Network(FCN)</strong>).<br>  Considering the weights and bias between input layer and hidden layer, we use the notation $w_{MD}^{(1)}$ for the weights between them. The superscript $(1)$ is the index and the subscript $MD$ indicates the size of $w$, $M$ is the number of hidden units and $D$ is the number of input units, due to the fully connection, the size of $w_{MD}^{(1)}$ is $M\times D$. Similarly, we know that $w_{KM}^{(02)}$ has the size $K\times M$. </p><h2 id="Programming"><a href="#Programming" class="headerlink" title="Programming"></a>Programming</h2><p>See GitHub repository <a href="https://github.com/sulxxy/ML_Algorithms/tree/master/MLP/">ML Algorithms&#x2F;MLP</a> for more details.</p><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><p>move error propagation to another post</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Bishop: Pattern Recognition and Machine Learning, Springer-Verlag, 2006</li></ol><h1 id="Further-More"><a href="#Further-More" class="headerlink" title="Further More"></a>Further More</h1><ol><li><a href="http://liuzhiwei.me/EM_GMM/">Expection Maximum and Gaussian Mixture Model</a></li><li><a href="http://liuzhiwei.me/CNN">Convolutional Neural Network</a></li><li><a href="http://liuzhiwei.me/RNN">Recurrent Neural Network</a></li><li><a href="http://liuzhiwei.me/RBF">Radical Basis Function</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Perceptron&quot;&gt;&lt;a href=&quot;#Perceptron&quot; class=&quot;headerlink&quot; title=&quot;Perceptron&quot;&gt;&lt;/a&gt;Perceptron&lt;/h1&gt;&lt;p&gt;Assume that only the means(or centroids) $\mathbf{\mu}_1$ and $\mathbf{\mu}_2$ of the 2 distributions are known. To predict the class of a new point, we could compare the distances to those 2 class means. That is,&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>EM Algorithm and Gaussian Mixture Model</title>
    <link href="http://www.liuzhiwei.me/em_gmm/"/>
    <id>http://www.liuzhiwei.me/em_gmm/</id>
    <published>2017-11-23T11:43:11.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction-to-EM"><a href="#Introduction-to-EM" class="headerlink" title="Introduction to EM"></a>Introduction to EM</h1><p>Previously I talked about <a href="http://liuzhiwei.me/Bayes_Classifier/">Naive Bayes Classifier</a>. In that case, all variables are observable. However, sometimes there could be some latent variables in some models. EM(Expection-Maximization) algorithm could resolve those models containing latent variables.</p><span id="more"></span><h1 id="Gaussian-Mixture-Models"><a href="#Gaussian-Mixture-Models" class="headerlink" title="Gaussian Mixture Models"></a>Gaussian Mixture Models</h1><p>Before talking general case of EM algorithm, we introduce the Gaussian Mixture Models(GMM) and calculate its parameters using EM.</p><h2 id="What-is-GMM"><a href="#What-is-GMM" class="headerlink" title="What is GMM?"></a>What is GMM?</h2><p>GMM is a composition of several components with Gaussian distribution and different components. It could be written like,<br>$$p(x) :&#x3D; \sum_{k&#x3D;1}^K \pi_k\mathcal{N}(x|\mu_k, , \Sigma_k) \tag{1}\label{eq:GMM}$$</p><p>Simply speaking, we can explain $\pi_k$ as the weights of each Gaussian.</p><p>However, in order to understand what the latent variable is and how it works, first we explain the formulation of the equation $\ref{eq:GMM}$ from the point of latent variables.</p><p>Imaging we have a K-dimensional binary vector $\mathcal{z}$ in which the $k^{th}$ element $\mathcal{i_k}$ equal to $\mathcal{1}$ and others are $\mathcal{0}$. Now we need to define $p(x, z)$:<br>$$p(x, z) :&#x3D; p(x|z)\cdot p(z)\tag{2}\label{eq:2}$$</p><p>in equation $\ref{eq:2}$, we need to consider $p(z)$ and $p(x|z)$. </p><ol><li><p>$p(z)$</p><p>$p(z)$ is the marginal distribution of $p(x, z)$ over $\mathcal{z}$, assuming it equals to the mixing coefficients $\pi_k$, so we have:<br>$$p(z_k &#x3D; 1) :&#x3D; \pi_k\tag{3}\label{eq:3}$$</p><p>since in vector $\mathcal{z}$, all values except \(\mathcal{z_k}\) are $\mathcal{0}$, so equation $\ref{eq:3}$ can be written like:</p><p>$$p(z) :&#x3D; \prod_{k&#x3D;1}^K \pi_k^{z_k}\tag{4}\label{eq:4}$$</p></li><li><p>$p(x|z)$</p><p>Also, assuming that the conditional distribution of $\mathcal{x}$ given a particular value for $\mathcal{z}$ is a Gaussian,<br>$$p(x|z_k&#x3D;1) :&#x3D; \mathcal{N}(x|\mu_k, , \Sigma_k)\tag{5}\label{eq:5}$$</p><p>Similarly, equation $\ref{eq:5}$ can be written like:<br>$$p(x|z) :&#x3D; \prod_{k&#x3D;1}^K \mathcal{N}(x|\mu_k, , \Sigma_k)^{z_k}\tag{6}\label{eq:6}$$</p></li></ol><p>Now we can calculate the marginal distribution of $p(x, z)$ over $\mathcal{x}$:<br>$$p(x) :&#x3D; \sum_{z} p(z)\cdot p(x|z)\tag{7}\label{eq:7}$$</p><p>put equation $\ref{eq:4}$ and $\ref{eq:6}$ into equation $\ref{eq:7}$,<br>$$p(x) :&#x3D; \sum_{k&#x3D;1}^K \pi_k \mathcal{N}(x|\mu_k, , \Sigma_k)\tag{8}\label{eq:8}$$</p><p>Equation $\ref{eq:8}$ is exactly same with equation $\ref{eq:GMM}$, so now we succefully explained the GMM from the point of latent variables.</p><p>Next, we need to calculate the conditional probability of $\mathcal{z}$ given $\mathcal{x}$, let us call it $\gamma(z_k)$,<br>$$\gamma(z_k) :&#x3D; p(z_k&#x3D;1|x) :&#x3D; \frac {p(z_k&#x3D;1)\cdot p(x|z_k&#x3D;1)}{p(x)}\tag{9}\label{eq:9}$$</p><p>put equation $\ref{eq:3}$, $\ref{eq:5}$ and $\ref{eq:8}$ into equation $\ref{eq:9}$,<br>$$\gamma(z_k) :&#x3D; \frac {\pi_k\mathcal{N}(\mu_k,,\Sigma_k)}{\sum_{j&#x3D;1}^K\mathcal{N}(x|\mu_j, , \Sigma_j)}\tag{10}\label{eq:10}$$</p><p>To prepare for the explaination using EM algorithm next, one important thing has to be emphasized:</p><ol><li>in equation $\ref{eq:8}$, $\pi_k$ should be seen as the <strong>prior</strong> of $z_k&#x3D;1$(this is what equation $\ref{eq:3}$ is saying);</li><li>in equation $\ref{eq:10}$, $\gamma(z_k)$ should be seen as <strong>posterior</strong> once we obeserved $\mathcal{x}$(this is what equation $\ref{eq:9}$ saying).</li></ol><h2 id="EM-algorithm-on-GMM"><a href="#EM-algorithm-on-GMM" class="headerlink" title="EM algorithm on GMM"></a>EM algorithm on GMM</h2><h1 id="EM-algorithm-in-general"><a href="#EM-algorithm-in-general" class="headerlink" title="EM algorithm in general"></a>EM algorithm in general</h1><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Bishop: Pattern Recognition and Machine Learning, Springer-Verlag, 2006</li><li>李航：统计学习方法，清华大学出版社，2012</li></ol><h1 id="related-Articles"><a href="#related-Articles" class="headerlink" title="related Articles"></a>related Articles</h1><ol start="0"><li>Bayesian Theory</li><li>K-means</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction-to-EM&quot;&gt;&lt;a href=&quot;#Introduction-to-EM&quot; class=&quot;headerlink&quot; title=&quot;Introduction to EM&quot;&gt;&lt;/a&gt;Introduction to EM&lt;/h1&gt;&lt;p&gt;Previously I talked about &lt;a href=&quot;http://liuzhiwei.me/Bayes_Classifier/&quot;&gt;Naive Bayes Classifier&lt;/a&gt;. In that case, all variables are observable. However, sometimes there could be some latent variables in some models. EM(Expection-Maximization) algorithm could resolve those models containing latent variables.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Bayes Classifier</title>
    <link href="http://www.liuzhiwei.me/bayes_classifier/"/>
    <id>http://www.liuzhiwei.me/bayes_classifier/</id>
    <published>2017-11-22T22:35:01.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="General-Idea"><a href="#General-Idea" class="headerlink" title="General Idea"></a>General Idea</h1><p>Generally speaking, to solve a classification problem, what we need to do is to get the optimal estimation on the posterior:<br>$$h(x) :&#x3D; \underset{c_k}{\arg \max} , P(Y&#x3D;c_k|X&#x3D;x) \tag{1}\label{eq:1}$$<br>There are 2 general methods to do this. First one is directly modeling the posterior based on training data and to do prediction based on that. This is called <strong>Discriminative Model</strong>, e.g., BP, LDA, SVM, etc. Another type is <strong>generative Models</strong>, which calculates $P(Y&#x3D;c_k|X&#x3D;x)$ using:<br>$$P(Y&#x3D;c_k|X&#x3D;x) :&#x3D; \frac {P(x,c_k)}{P(x)}\tag{2}\label{eq:2}$$<br>Naive Bayes Classifier is the second one.</p><span id="more"></span><h1 id="Naive-Bayes-Classifier"><a href="#Naive-Bayes-Classifier" class="headerlink" title="Naive Bayes Classifier"></a>Naive Bayes Classifier</h1><p>From Bayes Decision Theory, we know that:<br>$$P(X&#x3D;x, Y&#x3D;c_k) :&#x3D; P(X&#x3D;x|Y&#x3D;c_k)\cdot P(Y&#x3D;c_k)\tag{3}\label{eq:3}$$</p><p>put equation $\ref{eq:3}$  into equation $\ref{eq:2}$,<br>$$P(Y&#x3D;c_k|X&#x3D;x) :&#x3D; \frac {P(X&#x3D;x|Y&#x3D;c_k)\cdot P(Y&#x3D;c_k)}{P(x)}\tag{4}\label{eq:4}$$</p><p>put equation $\ref{eq:4}$ into $\ref{eq:1}$, we could get:<br>$$h(x) :&#x3D; \mathop{\arg,\max}\limits_{c_k}\frac {P(X&#x3D;x|Y&#x3D;c_k)\cdot P(Y&#x3D;c_k)}{P(x)}\tag{5}\label{eq:5}$$</p><p>Considered the divisor $P(x)$ is always the same no matter which class we finally choose, equation $\ref{eq:5}$ can be simplified to:<br>$$h(x) :&#x3D; \mathop{\arg,\max}\limits_{c_k} P(X&#x3D;x|Y&#x3D;c_k)\cdot P(Y&#x3D;c_k)\tag{6}\label{eq:6}$$</p><p>equation $\ref{eq:6}$ is the final objective function.</p><p>So now we need to calculate $P(X&#x3D;x|Y&#x3D;c_k)$ and $P(Y&#x3D;c_k)$. Let’s check them one by one.</p><ol><li><p>$P(X&#x3D;x|Y&#x3D;c_k)$</p><p>This term is called <strong>class-conditional probability</strong> or <strong>likelihood</strong>. It is hard to calculate directly since it could have lots of combinations for features of $x$. For example, $x$ has $d$ features, and each feature is a binary value(0 or 1). Even though in this pretty simple situation, there are still $2^d$ different combinations. However, it is impossible that the trainning data contains all of those combinations. That means, lots of combinations which do not appear in training dataset will be considered impossible happened(since $P(X&#x3D;x)&#x3D;0$). Obviously this is not correct.</p><p>To solve this problem, Naive Classifier assuming that:</p><blockquote><p>the value of a particular feature is independent of the value of any other feature, given the class variable</p></blockquote><p>Based on this assumption,<br>$$P(Y&#x3D;c_k|X&#x3D;x) :&#x3D; \prod_{i&#x3D;1}^{D} P(x_i|c_k)\tag{7}\label{eq:7}$$</p><p>In equation $\ref{eq:7}$,</p><ul><li>$D$ is the number of features of input data.</li></ul></li><li><p>$P(Y&#x3D;c_k)$</p><p>This term is called <strong>Prior</strong> and can be easily calculated using <strong>Maximum Likelihood Estimation</strong>,<br>$$P(Y&#x3D;c_k) :&#x3D;\frac {\sum_{i&#x3D;1}^N I(y_i&#x3D;{c_k})}{N}, \quad k&#x3D;1, 2, 3, … , K \tag{8}\label{eq:8}$$</p><p>In equation $\ref{eq:8}$,</p><ul><li>$I$ is a Indicator function. </li><li>$K$ is the number of classes.</li><li>$N$ is the number of samples.</li></ul></li></ol><p>Now put $\ref{eq:7}$ and $\ref{eq:8}$ into $\ref{eq:6}$, the updated objective function is,<br>$$h(x) :&#x3D; \mathop{\arg,\max}\limits_{c_k} \prod_{i&#x3D;1}^{D} P(x_i|c_k) \cdot P(Y&#x3D;c_k), \quad k &#x3D; 1,2,…,K \tag{9}\label{eq:9}$$</p><p>Equation $\ref{eq:9}$ is the Naive Bayes Classifier expression.</p><h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="Laplacian-Correction"><a href="#Laplacian-Correction" class="headerlink" title="Laplacian Correction"></a>Laplacian Correction</h2><h2 id="Semi-Naive-Bayes-Classifier"><a href="#Semi-Naive-Bayes-Classifier" class="headerlink" title="Semi-Naive Bayes Classifier"></a>Semi-Naive Bayes Classifier</h2><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>[todo]</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;General-Idea&quot;&gt;&lt;a href=&quot;#General-Idea&quot; class=&quot;headerlink&quot; title=&quot;General Idea&quot;&gt;&lt;/a&gt;General Idea&lt;/h1&gt;&lt;p&gt;Generally speaking, to solve a classification problem, what we need to do is to get the optimal estimation on the posterior:&lt;br&gt;$$h(x) :&amp;#x3D; \underset{c_k}{\arg \max} , P(Y&amp;#x3D;c_k|X&amp;#x3D;x) \tag{1}\label{eq:1}$$&lt;br&gt;There are 2 general methods to do this. First one is directly modeling the posterior based on training data and to do prediction based on that. This is called &lt;strong&gt;Discriminative Model&lt;/strong&gt;, e.g., BP, LDA, SVM, etc. Another type is &lt;strong&gt;generative Models&lt;/strong&gt;, which calculates $P(Y&amp;#x3D;c_k|X&amp;#x3D;x)$ using:&lt;br&gt;$$P(Y&amp;#x3D;c_k|X&amp;#x3D;x) :&amp;#x3D; \frac {P(x,c_k)}{P(x)}\tag{2}\label{eq:2}$$&lt;br&gt;Naive Bayes Classifier is the second one.&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Backpropagation Algorithm</title>
    <link href="http://www.liuzhiwei.me/back_propagation/"/>
    <id>http://www.liuzhiwei.me/back_propagation/</id>
    <published>2017-10-22T22:35:01.000Z</published>
    <updated>2022-08-21T13:06:29.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Feed-forward-Network"><a href="#Feed-forward-Network" class="headerlink" title="Feed-forward Network"></a>Feed-forward Network</h1><p>Considering a basic network architecture, first a linear combination of input data $x_1, \ldots, x_D$:</p><span id="more"></span><p>$$a_j &#x3D; \sum_{i&#x3D;1}^D\mathcal{w}_{ji}^{(1)}x_{i}+\mathcal{w}_{j0}^{(1)} \label{eq:1} \tag{1}$$<br>where $j&#x3D;1, \ldots, M$.<br>Then each of this is transformed using a nonlinear <em>activation function h()</em>,<br>$$ z_j &#x3D; h(a_j)  \label{eq:2} \tag{2} $$<br>At the end, these values are linear combined again using <em>output unit activations</em>:<br>$$ a_k &#x3D; \sum_{j&#x3D;1}^{M}\mathcal{w}_{kj}^{(2)} + \mathcal{w}_{k0}^{(2)} \label{eq:3} \tag{3} $$<br>To merge all we got:<br>$$ y_k(\mathbf{x}, \mathbf{w}) &#x3D; \sigma\Biggl(\sum_{j&#x3D;1}^Mw_{kj}^{(2)}h\biggl(\sum_{i&#x3D;1}^Dw_{ji}^{(1)}x_i + w_{j0}^{(1)}\biggr) + w_{k0}^{(2)}\Biggr) \label{eq:4} \tag{4} $$<br>if we absorb the biases, $(\ref{eq:4})$ could be simplified like:<br>$$ y_k(\mathbf{x}, \mathbf{w}) &#x3D; \sigma\Biggl(\sum_{j&#x3D;0}^Mw_{kj}^{(2)}h\biggl(\sum_{i&#x3D;0}^Dw_{ji}^{(1)}x_i \biggr) \Biggr) \label{eq:5} \tag{5} $$</p><h1 id="Network-Training"><a href="#Network-Training" class="headerlink" title="Network Training"></a>Network Training</h1><p>Now we have the network architecture. Next step is to define the error cost function. Simply speaking, it could be defined like:<br>$$ E(\mathbf{w}) &#x3D; \frac{1}{2}\sum_{n&#x3D;1}^{N}{\Vert \mathbf{y}(\mathbf{x}_n, \mathbf{w}) - t_n\Vert}^{2} \label{eq:6} \tag{6} $$<br>In particular, this cost function could be interpreted from probabilistic perspective. [todo, explain this using probabilistic interpretation].</p><h1 id="Error-Backpropagation"><a href="#Error-Backpropagation" class="headerlink" title="Error Backpropagation"></a>Error Backpropagation</h1><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><ol><li>todo, explain ($\ref{eq:6}$) using probabilistic interpretation</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Feed-forward-Network&quot;&gt;&lt;a href=&quot;#Feed-forward-Network&quot; class=&quot;headerlink&quot; title=&quot;Feed-forward Network&quot;&gt;&lt;/a&gt;Feed-forward Network&lt;/h1&gt;&lt;p&gt;Considering a basic network architecture, first a linear combination of input data $x_1, \ldots, x_D$:&lt;/p&gt;</summary>
    
    
    
    <category term="machine_learning" scheme="http://www.liuzhiwei.me/categories/machine-learning/"/>
    
    
  </entry>
  
</feed>
