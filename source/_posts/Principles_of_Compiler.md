title: Principles of Compiler
date: 2016-04-10 16:12:45
categories: Curriculum Summary
tags: [Compiler]
---

# Description
---
In this course, we mainly talked about the basic steps and principles about a compiler. There are 5 steps while compiling:
1. Lexical analysis
2. Syntax analysis
3. Semantic analysis
4. Intermediate code generator
5. Target code generator

There are 2 components through out the compiling process:
1. Symbol table
2. Error handler

# Lexical analysis
---
## General process of lexical analysis
1. **Input**: a string
2. **Output**: a table which marks all of the **lexemes** with their corresponding **tokens** from the input string.
3. **Details**: we can use regular expressions to describe a token, and use finite automata to recognize a token.

## Regular Expression
Regular Expression is a powerful tool to describe strings. In compilers, regular expressions are used to describe tokens. 
e.g. a|b = {a, b}
(ab)\* = {ε, ab, abab, ababab, ...}
char = [a-zA-Z]
digit =  [0-9]  \\d
Optional: ?

## NFA: Non-deterministic Finite Automata
A non-deterministic finite automata consists of:
1. A finite set of states *S*;
2. A set of input symbols ∑, the *input alphabet*.
3. A *transition function* that gives, for each state, and for each symbol in ∑U{ε} a set of *next states*.
4. A state *s0* from *S* that is distinguished as the *initial state*.
5. A set of states *F*, a subset of *S*, that is distinguished as the accepting states(or final states);

## DFA: Deterministic Finite Automata
A deterministic finite automata is a special case of an NFA where:
1. There are no moves on input ε, and
2. For each state *s* and input symbol *a*, there is exactly one edge out of *s* labeled *a*.

## From regular expressions to automata
1. Thompson algorithm 
[TODO Figure]
2. From NFA to DFA
	1. Calculate the ε_closure of start state;
	2. Calculate the ε_closure of smove;
	3. e.g. [TODO]

# Syntax analysis
---
## General process of syntax analysis
1. **Input**: Tokens from lexical analyzer
2. **Output**: Parse tree

## CFG: Context Free Grammar
A context free grammar consists of:
1. *Terminals* are the basic symbols from which strings are formed. The term "token name" is a synonym for "terminal".
2. *Non-terminals* are syntactic variables that denote sets of strings. The sets of strings denoted by non-terminals help define the language generated by the grammar.
3. In a grammar, one non-terminal is distinguished as the *start symbol*. The productions for the start symbol are listed first.
4. The *productions* of a grammar specify the manner in which the terminals and non-terminals can be combined to form strings.
5. An example of arithmetic expressions:
{% codeblock %}
N={E}, T={+,*,(,),-,id}, S=E
P: E -> E + E;
   E -> E * E;
   E -> (E);
   E -> -E;
   E -> id;
{% endcodeblock %}
6. Derivations

## Top-Down Syntax Analysis
1. Elimination of ambiguity
2. Elimination of left recursion
3. Elimination of left factor
4. Top-Down parsing
5. Predictive parsing table

## Bottom-Up Syntax Analysis
1. Reduction
2. Shift-Reduce parsing
3. SLR parsing table

# Semantic analysis
---
1. SDD: Syntax-Directed Definition
A syntax-directed definition is a context-free grammar together with attributes and rules.
	1. Inherited Attributes[TODO Figure]
	Top-Down, including brothers
	2. Synthesized attributes
	Bottom-Up, including itself

# Intermediate code generator
---

